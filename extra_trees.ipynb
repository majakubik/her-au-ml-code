{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2060a6d6",
   "metadata": {},
   "source": [
    "### 0. Libraries and global setup\n",
    "The code requires scikit-learn version 1.1 or later, fixed random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d23623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error, median_absolute_error, r2_score)\n",
    "\n",
    "from sklearn.model_selection import (GridSearchCV, GroupShuffleSplit, ParameterGrid, StratifiedGroupKFold)\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "RND = 42  # fixed seed across splits and models\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "\n",
    "FEATURE_FILE = DATA_PROCESSED / \"mamun_HER_features.csv\"\n",
    "df = pd.read_csv(FEATURE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c62c1",
   "metadata": {},
   "source": [
    "### 1. Load and basic wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53756639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset load\n",
    "df = pd.read_csv(FEATURE_FILE)\n",
    "df = df.rename(columns={\"reactionEnergy_eV\": \"Eads\"})\n",
    "\n",
    "# mark Au-containing rows\n",
    "df[\"is_Au\"] = df[[\"surf_A\", \"surf_B\"]].apply(lambda r: \"Au\" in r.values, axis=1)\n",
    "\n",
    "# target and features definition\n",
    "target = \"Eads\"\n",
    "feature_cols = [\"facet\", \"SA\", \"SB\", \"GCN\", \"WAR\", \"WEN\", \"WIE\", \"Psi\", \"vol_per_atom\"]\n",
    "num_cols = feature_cols[:]  # all treated as numeric in this pipeline\n",
    "\n",
    "# group ID definitions for \"systems\" (order-invariant surf pair + facet + site)\n",
    "surf_pair = df[[\"surf_A\", \"surf_B\"]].astype(str).apply(lambda r: \"-\".join(sorted(r)), axis=1)\n",
    "sys_id = surf_pair + \"_\" + df[\"facet\"].astype(str) + \"_\" + df[\"site_simple_collapsed\"].astype(str)\n",
    "# sys_id is used for both the outer train/test split and CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328c5b3",
   "metadata": {},
   "source": [
    "### 2. Data split\n",
    "Group aware 80/20 outer train/test split by system, Au-containing systems share in the test/train set is emergent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13fe7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=RND)\n",
    "tr_idx, te_idx = next(gss.split(df, groups=sys_id))\n",
    "\n",
    "train_df = df.iloc[tr_idx].copy()\n",
    "test_df = df.iloc[te_idx].copy()\n",
    "\n",
    "X_train, y_train = train_df[feature_cols], train_df[target]\n",
    "X_test, y_test = test_df[feature_cols], test_df[target]\n",
    "\n",
    "# group IDs for cross-validation on the training set\n",
    "groups_train = sys_id.loc[X_train.index].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b3dfa",
   "metadata": {},
   "source": [
    "### 3. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = ColumnTransformer([(\"num\", MinMaxScaler(), num_cols)]) # optional for Extra Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c7522",
   "metadata": {},
   "source": [
    "### 4. ExtraTrees Regressor\n",
    "Extra Trees Regressor with the hyperparameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr = ExtraTreesRegressor(random_state=RND)\n",
    "\n",
    "param_grid = {\n",
    "    \"extr__n_estimators\": [1000],\n",
    "    \"extr__max_features\": list(range(1, len(feature_cols) + 1)) + [\"sqrt\"],\n",
    "    \"extr__max_depth\": [100, 300, 600, 900],\n",
    "    \"extr__min_samples_split\": [2, 3, 4],\n",
    "}\n",
    "\n",
    "pipe = Pipeline([(\"pre\", pre), (\"extr\", extr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab6e9f",
   "metadata": {},
   "source": [
    "### 5. Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_labels = train_df.loc[X_train.index, \"is_Au\"].astype(int).values\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=RND)\n",
    "\n",
    "# precompute splits to pass y_train to the model and stratify on is_Au\n",
    "cv = list(sgkf.split(X_train, y=strat_labels, groups=groups_train))\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,              \n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a5791",
   "metadata": {},
   "source": [
    "### 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "mask_au = test_df[\"is_Au\"].values.astype(bool)\n",
    "mask_non_au = ~mask_au\n",
    "\n",
    "def show_metrics(label, y_true, y_hat):\n",
    "    mae = mean_absolute_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_hat))\n",
    "    r2 = r2_score(y_true, y_hat)\n",
    "    mad = median_absolute_error(y_true, y_hat)\n",
    "    print(f\"{label:12s} | MAE: {mae:.4f}  RMSE: {rmse:.4f}  RÂ²: {r2:.4f}  MAD: {mad:.4f}\")\n",
    "\n",
    "print(f\"\\nGroup-aware test set: {len(test_df)} rows \" \n",
    "      f\"({mask_au.sum()} Au, {mask_non_au.sum()} non-Au)\")\n",
    "\n",
    "show_metrics(\"All rows\", y_test, y_pred)\n",
    "show_metrics(\"Au only\", y_test[mask_au], y_pred[mask_au])\n",
    "show_metrics(\"non-Au only\", y_test[mask_non_au], y_pred[mask_non_au])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6219e6a",
   "metadata": {},
   "source": [
    "### 7. Per-fold metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b89079",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_labels = train_df.loc[X_train.index, \"is_Au\"].astype(int).values\n",
    "\n",
    "rows = []\n",
    "for k, (tr, va) in enumerate(cv, start=1): # reuse precomputed SGKF splits\n",
    "    est = clone(grid.best_estimator_) # same pipeline with best hyperparams\n",
    "    est.fit(X_train.iloc[tr], y_train.iloc[tr])\n",
    "    y_hat = est.predict(X_train.iloc[va])\n",
    "\n",
    "    y_true = y_train.iloc[va]\n",
    "    mae_all = mean_absolute_error(y_true, y_hat)\n",
    "\n",
    "    au_mask = (strat_labels[va] == 1)\n",
    "    mae_au = mean_absolute_error(y_true[au_mask], y_hat[au_mask]) if au_mask.any() else np.nan\n",
    "\n",
    "    rows.append({\"Fold\": k, \"MAE_all\": mae_all, \"MAE_Au\": mae_au})\n",
    "\n",
    "per_fold = pd.DataFrame(rows, columns=[\"Fold\", \"MAE_all\", \"MAE_Au\"])\n",
    "print(per_fold.to_string(index=False))\n",
    "print(\"Mean MAE_all:\", per_fold[\"MAE_all\"].mean())\n",
    "print(\"Mean MAE_Au:\", np.nanmean(per_fold[\"MAE_Au\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
